{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OEbE99mgIVU",
        "outputId": "c371445b-5b3b-4482-8e04-d0c70ed5997c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/DeepLearning_HW2\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/DeepLearning_HW2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3zenp2AoVvI",
        "outputId": "09d83a12-58c7-4fad-b5a4-49990c120235"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all_plants_data  archive.zip  hw#2  Plants_2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd ./Plants_2/"
      ],
      "metadata": {
        "id": "7qCOlICBoWx0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils import data\n",
        "from torch.autograd import Variable"
      ],
      "metadata": {
        "id": "xJmyS5yMp0SC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_WIDTH = 224  # width of image\n",
        "IMG_HEIGHT = 224  # height of image\n",
        "# BATCH_SIZE = 32  # batch size\n",
        "# SEED = 0  # random seed\n",
        "# DROPOUT = 0.5  # dropout probability\n",
        "# LEARNING_RATE = 0.001    # learning rate\n",
        "# NUM_EPOCHS = 10   # number of epochs\n",
        "# CNN_MODEL_PATH = 'cnn_classification_model.pt'  # path for saved CNN model\n",
        "# NUM_CLASSES = 2 "
      ],
      "metadata": {
        "id": "TbAJT_aiqMs-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformation = transforms.Compose([\n",
        "        # resize\n",
        "        transforms.Resize((IMG_HEIGHT, IMG_WIDTH)),\n",
        "        # transform to tensors\n",
        "        transforms.ToTensor(),\n",
        "        # normalize\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])"
      ],
      "metadata": {
        "id": "LjRKD6liqK3w"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "train_folder = \"./Plants_2/train/\"\n",
        "train_dataset = datasets.ImageFolder(root = train_folder, \n",
        "                transform = transformation)\n",
        "\n",
        "train_loader = data.DataLoader(train_dataset, batch_size = 8, shuffle = True)"
      ],
      "metadata": {
        "id": "FrBeLQxo0L_r"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_folder = \"./Plants_2/valid/\"\n",
        "val_dataset = datasets.ImageFolder(root = val_folder, \n",
        "                transform = transformation)\n",
        "\n",
        "val_loader = data.DataLoader(val_dataset, batch_size = 8, shuffle = True)"
      ],
      "metadata": {
        "id": "d4qMHMzIvkmA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_folder = \"./Plants_2/test/\"\n",
        "test_dataset = datasets.ImageFolder(root = test_folder, \n",
        "                transform = transformation)\n",
        "\n",
        "test_loader = data.DataLoader(test_dataset, batch_size = 8, shuffle = True)"
      ],
      "metadata": {
        "id": "eYewQavv0z2z"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 12, 4, stride=2, padding=1),           \n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(12, 24, 4, stride=2, padding=1),           \n",
        "            nn.ReLU(),\n",
        "\t\t\tnn.Conv2d(24, 48, 4, stride=2, padding=1),           \n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "\t\t\tnn.ConvTranspose2d(48, 24, 4, stride=2, padding=1),  # [batch, 24, 8, 8]\n",
        "            nn.ReLU(),\n",
        "\t\t\tnn.ConvTranspose2d(24, 12, 4, stride=2, padding=1),  # [batch, 12, 16, 16]\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(12, 3, 4, stride=2, padding=1),   # [batch, 3, 32, 32]\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return encoded, decoded"
      ],
      "metadata": {
        "id": "8kVF-zUrr_2i"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "    autoencoder = Autoencoder()\n",
        "    print_model(autoencoder.encoder, autoencoder.decoder)\n",
        "    if torch.cuda.is_available():\n",
        "        autoencoder = autoencoder.cuda()\n",
        "        print(\"Model moved to GPU in order to speed up training.\")\n",
        "    return autoencoder\n",
        "\n",
        "def print_model(encoder, decoder):\n",
        "    print(\"============== Encoder ==============\")\n",
        "    print(encoder)\n",
        "    print(\"============== Decoder ==============\")\n",
        "    print(decoder)\n",
        "    print(\"\")"
      ],
      "metadata": {
        "id": "MorabIEwqURO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder = create_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJTa4E6SolYs",
        "outputId": "22346f11-1e82-4a93-883d-1ae5d0fa9069"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============== Encoder ==============\n",
            "Sequential(\n",
            "  (0): Conv2d(3, 12, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "  (1): ReLU()\n",
            "  (2): Conv2d(12, 24, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "  (3): ReLU()\n",
            "  (4): Conv2d(24, 48, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "  (5): ReLU()\n",
            ")\n",
            "============== Decoder ==============\n",
            "Sequential(\n",
            "  (0): ConvTranspose2d(48, 24, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "  (1): ReLU()\n",
            "  (2): ConvTranspose2d(24, 12, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "  (3): ReLU()\n",
            "  (4): ConvTranspose2d(12, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "  (5): Tanh()\n",
            ")\n",
            "\n",
            "Model moved to GPU in order to speed up training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_torch_vars(x):\n",
        "    if torch.cuda.is_available():\n",
        "        x = x.cuda()\n",
        "    return Variable(x)"
      ],
      "metadata": {
        "id": "Eo9nuKAh3GuP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# criterion = nn.BCELoss()\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = optim.Adam(autoencoder.parameters())\n",
        "\n",
        "for epoch in range(100):\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, _) in enumerate(train_loader, 0):\n",
        "        inputs = get_torch_vars(inputs)\n",
        "        # ============ Forward ============\n",
        "        encoded, outputs = autoencoder(inputs)\n",
        "        loss = criterion(outputs, inputs)\n",
        "        # ============ Backward ============\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # ============ Logging ============\n",
        "        running_loss += loss.data\n",
        "        if i % 5 == 4:\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPQj2HGh1_g5",
        "outputId": "1a8bde28-3618-4ecf-d65e-ffa09a9c3a01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,     5] loss: 0.003\n",
            "[1,    10] loss: 0.002\n",
            "[1,    15] loss: 0.002\n",
            "[1,    20] loss: 0.001\n",
            "[1,    25] loss: 0.001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VVMW9_ul3H_x"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}